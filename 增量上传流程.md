# 增量上传流程

## 注意事项

- 读取文件时确保读入数据类型为有符号，长度为一字节，保证不同语言实现时 md5 和 adler32 算法结果一致。具体在c++中数据类型为 char.
- Adler32 算法计算结果为无符号类型，保证一致。

## 流程

增量上传使用了rsync算法, 流程如下

1. 服务器对已有文件进行分块，并存储，结构如下:

```json
{
    "fileRefId": "12345",
    "size": 1024, // data每块大小
    "data": [
        { "id": 0, "adler32": 123123123, "md5": "abcdefg" },
        // ...
    ]
}
```

2. 客户端上传时参数提供 fileId.

3. 服务器根据 fileId 以及文件当前版本获取到 fileRefId, 并根据 fileRefId 获取分块信息。将分块信息和 fileId, version 一同返回客户端。

4. 客户端根据分块信息和本地文件，通过 rsync 算法算出增量信息，并将 fileId, version 和增量信息一起传给服务器，信息结构如下:

```json
{
    "fileId": "12345",
    "version": 0,
    "data": [
        {
            "type": 1, // 1 - 分块
            "chunkId": 123 // 块对应 id
        },
        {
            "type": 2, // 2 - 增量数据
            "data": [ 1,2,3,4,5 ] // uint8 数据，我们统一使用无符号类型
        }
    ]
}
```

5. 服务端根据客户端提供 fileId, version 拿到源文件，并使用客户端提供的增量信息和源文件，拼出新文件，算法如下:

```cpp
typedef struct {
    uint32_t a;
    uint32_t b;
    uint32_t s;
} AdlerResult;

typedef struct {
    int64_t id;
    AdlerResult ad32;
    std::string md5;
    size_t offset;
    size_t size;
} Chunk;

class Package {
public:
    int type; // 1 - chunk, 2 - data
    Chunk chunk;
    std::vector<unsigned char> data;
};

void writeResult(const string& topath, const vector<unsigned char>& originFile, const vector<Package>& result) {
    ofstream out_file(topath, ofstream::binary);
    assert(out_file.is_open());
    for (const auto& package : result) {
        if (package.type == 1) {
            // chunk
            auto offset = package.chunk.offset;
            out_file.write((char*)(originFile.data() + offset), package.chunk.size);
        } else {
            // data
            out_file.write((char*)package.data.data(), package.data.size());
        }
    }
    out_file.flush();
    out_file.close();
}
```

其中实际计算时，源文件 originFile 不需要全部读进内存，只需按需读取内容并写入新文件

6. 客户端可以提供相应数据如文件md5值，确保新文件正确性。

7. 按照第一步的结构对新文件进行分块，并存入数据库。

## 文件分块策略

...
